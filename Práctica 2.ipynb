{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica de extracción de entidades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Asignatura Data Science para la Informacion no Estructurada. Ricardo Ocaña Martinez*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La presente práctica consiste en realizar un script que extraiga las entidades que se presenten en un texto. Las entidades a extraer serán de tipo organización, localización y persona.\n",
    "\n",
    "Para realizar esta tarea se utilizará un sistema ya entrenado, fundamentalmente el entrenamiento con que se cuenta en NLTK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las librerías que vamos a necesitar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy\n",
    "import nltk, re, pprint\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk.corpus import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtenga dos ficheros en formato txt, uno de ellos en ingles y otro en español, que contengan textos con entidades a extraer. Busque textos con un conjunto amplio de entidades, no se limite a dos o tres de cada tipo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el texto en Español sobre un titular de noticias de la pagina web Cinco Dias de El Pais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "entidades_espanol= open('EntidadesEspanol.txt')\n",
    "texto_espanol = entidades_espanol.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos aseguramos que detecta el idioma en español."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Idioma:  es\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nIdioma: \", textacy.text_utils.detect_language(str(texto_espanol)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos lo mismo con el texto en inglés. Para el texto en inglés hemos escogido un titular de periodico briánico Mirror, que habla sobre el conflicto Brexit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "entidades_ingles= open('EntidadesEnglish.txt')\n",
    "texto_ingles = entidades_ingles.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Idioma:  en\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nIdioma: \", textacy.text_utils.detect_language(str(texto_ingles)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lea estos textos desde un programa Python, y realice las labores de pre-procesamiento habituales: división en frases, división en palabras y conversión a las formas normales. Utilice instrucciones como sent_tokenize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ello dividiremos el texto en frases, palabras y conversión a las formas formales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pese a las cada vez más duras demandas de capital la banca española ha logrado superar las nuevas exigencias, con lo que no tienen limitaciones para repartir dividendo, pagar bonus a sus directivos o abonar los cupones de los bonos convertibles a lo largo del presente ejericico.', 'No obstante, los supervisores mantienen su objetivo de elevar los ratios de capital para el presente ejercicio, “y lo mismo harán para 2020”, explica otra fuente financiera.', 'De momento, Deutsche Bank e ING son los bancos a los que se les exige más requerimientos de capital total, seguido de BNG también de los Países Bajos, al alemán Commezbank (que negocia su fusión con Deutsche Bank), y a al italiano Monte dei Paschi dei Siena.']\n"
     ]
    }
   ],
   "source": [
    "frases = nltk.sent_tokenize(texto_espanol)\n",
    "print(frases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pese', 'a', 'las', 'cada', 'vez', 'más', 'duras', 'demandas', 'de', 'capital', 'la', 'banca', 'española', 'ha', 'logrado', 'superar', 'las', 'nuevas', 'exigencias', ',', 'con', 'lo', 'que', 'no', 'tienen', 'limitaciones', 'para', 'repartir', 'dividendo', ',', 'pagar', 'bonus', 'a', 'sus', 'directivos', 'o', 'abonar', 'los', 'cupones', 'de', 'los', 'bonos', 'convertibles', 'a', 'lo', 'largo', 'del', 'presente', 'ejericico', '.', 'No', 'obstante', ',', 'los', 'supervisores', 'mantienen', 'su', 'objetivo', 'de', 'elevar', 'los', 'ratios', 'de', 'capital', 'para', 'el', 'presente', 'ejercicio', ',', '“', 'y', 'lo', 'mismo', 'harán', 'para', '2020', '”', ',', 'explica', 'otra', 'fuente', 'financiera', '.', 'De', 'momento', ',', 'Deutsche', 'Bank', 'e', 'ING', 'son', 'los', 'bancos', 'a', 'los', 'que', 'se', 'les', 'exige', 'más', 'requerimientos', 'de', 'capital', 'total', ',', 'seguido', 'de', 'BNG', 'también', 'de', 'los', 'Países', 'Bajos', ',', 'al', 'alemán', 'Commezbank', '(', 'que', 'negocia', 'su', 'fusión', 'con', 'Deutsche', 'Bank', ')', ',', 'y', 'a', 'al', 'italiano', 'Monte', 'dei', 'Paschi', 'dei', 'Siena', '.']\n"
     ]
    }
   ],
   "source": [
    "palabras = nltk.word_tokenize(texto_espanol)\n",
    "print(palabras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lemas\n",
      "Pese                Pese                \n",
      "a                   a                   \n",
      "las                 las                 \n",
      "cada                cada                \n",
      "vez                 vez                 \n",
      "más                 más                 \n",
      "duras               duras               \n",
      "demandas            demandas            \n",
      "de                  de                  \n",
      "capital             capital             \n",
      "la                  la                  \n",
      "banca               banca               \n",
      "española            española            \n",
      "ha                  ha                  \n",
      "logrado             logrado             \n",
      "superar             superar             \n",
      "las                 las                 \n",
      "nuevas              nuevas              \n",
      "exigencias          exigencias          \n",
      ",                   ,                   \n",
      "con                 con                 \n",
      "lo                  lo                  \n",
      "que                 que                 \n",
      "no                  no                  \n",
      "tienen              tienen              \n",
      "limitaciones        limitaciones        \n",
      "para                para                \n",
      "repartir            repartir            \n",
      "dividendo           dividendo           \n",
      ",                   ,                   \n",
      "pagar               pagar               \n",
      "bonus               bonus               \n",
      "a                   a                   \n",
      "sus                 sus                 \n",
      "directivos          directivos          \n",
      "o                   o                   \n",
      "abonar              abonar              \n",
      "los                 los                 \n",
      "cupones             cupones             \n",
      "de                  de                  \n",
      "los                 los                 \n",
      "bonos               bonos               \n",
      "convertibles        convertibles        \n",
      "a                   a                   \n",
      "lo                  lo                  \n",
      "largo               largo               \n",
      "del                 del                 \n",
      "presente            presente            \n",
      "ejericico           ejericico           \n",
      ".                   .                   \n",
      "No                  No                  \n",
      "obstante            obstante            \n",
      ",                   ,                   \n",
      "los                 los                 \n",
      "supervisores        supervisores        \n",
      "mantienen           mantienen           \n",
      "su                  su                  \n",
      "objetivo            objetivo            \n",
      "de                  de                  \n",
      "elevar              elevar              \n",
      "los                 los                 \n",
      "ratios              ratios              \n",
      "de                  de                  \n",
      "capital             capital             \n",
      "para                para                \n",
      "el                  el                  \n",
      "presente            presente            \n",
      "ejercicio           ejercicio           \n",
      ",                   ,                   \n",
      "“                   “                   \n",
      "y                   y                   \n",
      "lo                  lo                  \n",
      "mismo               mismo               \n",
      "harán               harán               \n",
      "para                para                \n",
      "2020                2020                \n",
      "”                   ”                   \n",
      ",                   ,                   \n",
      "explica             explica             \n",
      "otra                otra                \n",
      "fuente              fuente              \n",
      "financiera          financiera          \n",
      ".                   .                   \n",
      "De                  De                  \n",
      "momento             momento             \n",
      ",                   ,                   \n",
      "Deutsche            Deutsche            \n",
      "Bank                Bank                \n",
      "e                   e                   \n",
      "ING                 ING                 \n",
      "son                 son                 \n",
      "los                 los                 \n",
      "bancos              bancos              \n",
      "a                   a                   \n",
      "los                 los                 \n",
      "que                 que                 \n",
      "se                  se                  \n",
      "les                 les                 \n",
      "exige               exige               \n",
      "más                 más                 \n",
      "requerimientos      requerimientos      \n",
      "de                  de                  \n",
      "capital             capital             \n",
      "total               total               \n",
      ",                   ,                   \n",
      "seguido             seguido             \n",
      "de                  de                  \n",
      "BNG                 BNG                 \n",
      "también             también             \n",
      "de                  de                  \n",
      "los                 los                 \n",
      "Países              Países              \n",
      "Bajos               Bajos               \n",
      ",                   ,                   \n",
      "al                  al                  \n",
      "alemán              alemán              \n",
      "Commezbank          Commezbank          \n",
      "(                   (                   \n",
      "que                 que                 \n",
      "negocia             negocia             \n",
      "su                  su                  \n",
      "fusión              fusión              \n",
      "con                 con                 \n",
      "Deutsche            Deutsche            \n",
      "Bank                Bank                \n",
      ")                   )                   \n",
      ",                   ,                   \n",
      "y                   y                   \n",
      "a                   a                   \n",
      "al                  al                  \n",
      "italiano            italiano            \n",
      "Monte               Monte               \n",
      "dei                 dei                 \n",
      "Paschi              Paschi              \n",
      "dei                 dei                 \n",
      "Siena               Siena               \n",
      ".                   .                   \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLemas\")\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "for palabra in palabras:\n",
    "    print (\"{0:20}{1:20}\".format(palabra,wordnet_lemmatizer.lemmatize(palabra, pos=\"v\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phrases:  The New IRA are capitalising on Brexit to recruit, senior members have admitted.\n",
      "\n",
      "The Paramilitary group, who last week accepted responsibility for the killing of journalist Lyra McKee, said it would be \"remiss\" of them not to take advantage of the row over the Northern Irish border.\n",
      "\n",
      "But in an interview with the Sunday Times, representatives admitted their campaign of violence had no chance of achieving their goal of a united Ireland.\n",
      "They said: \"The attacks are symbolic. They are propaganda. As long as you have the British in Ireland and the country remains partitioned, there will be an IRA.\"\n",
      "\n",
      "One dissident told the Times: \" Brexit has forced the IRA to refocus and has underlined how Ireland remains partitioned. It would be remiss of us not to capitalise on the opportunity\"\n"
     ]
    }
   ],
   "source": [
    "phrases = nltk.sent_tokenize(str(texto_ingles))\n",
    "print(\"\\nPhrases: \", texto_ingles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'New', 'IRA', 'are', 'capitalising', 'on', 'Brexit', 'to', 'recruit', ',', 'senior', 'members', 'have', 'admitted', '.', 'The', 'Paramilitary', 'group', ',', 'who', 'last', 'week', 'accepted', 'responsibility', 'for', 'the', 'killing', 'of', 'journalist', 'Lyra', 'McKee', ',', 'said', 'it', 'would', 'be', '``', 'remiss', \"''\", 'of', 'them', 'not', 'to', 'take', 'advantage', 'of', 'the', 'row', 'over', 'the', 'Northern', 'Irish', 'border', '.', 'But', 'in', 'an', 'interview', 'with', 'the', 'Sunday', 'Times', ',', 'representatives', 'admitted', 'their', 'campaign', 'of', 'violence', 'had', 'no', 'chance', 'of', 'achieving', 'their', 'goal', 'of', 'a', 'united', 'Ireland', '.', 'They', 'said', ':', '``', 'The', 'attacks', 'are', 'symbolic', '.', 'They', 'are', 'propaganda', '.', 'As', 'long', 'as', 'you', 'have', 'the', 'British', 'in', 'Ireland', 'and', 'the', 'country', 'remains', 'partitioned', ',', 'there', 'will', 'be', 'an', 'IRA', '.', \"''\", 'One', 'dissident', 'told', 'the', 'Times', ':', '``', 'Brexit', 'has', 'forced', 'the', 'IRA', 'to', 'refocus', 'and', 'has', 'underlined', 'how', 'Ireland', 'remains', 'partitioned', '.', 'It', 'would', 'be', 'remiss', 'of', 'us', 'not', 'to', 'capitalise', 'on', 'the', 'opportunity', \"''\"]\n"
     ]
    }
   ],
   "source": [
    "words = nltk.word_tokenize(texto_ingles)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lemas\n",
      "The                 The                 \n",
      "New                 New                 \n",
      "IRA                 IRA                 \n",
      "are                 be                  \n",
      "capitalising        capitalise          \n",
      "on                  on                  \n",
      "Brexit              Brexit              \n",
      "to                  to                  \n",
      "recruit             recruit             \n",
      ",                   ,                   \n",
      "senior              senior              \n",
      "members             members             \n",
      "have                have                \n",
      "admitted            admit               \n",
      ".                   .                   \n",
      "The                 The                 \n",
      "Paramilitary        Paramilitary        \n",
      "group               group               \n",
      ",                   ,                   \n",
      "who                 who                 \n",
      "last                last                \n",
      "week                week                \n",
      "accepted            accept              \n",
      "responsibility      responsibility      \n",
      "for                 for                 \n",
      "the                 the                 \n",
      "killing             kill                \n",
      "of                  of                  \n",
      "journalist          journalist          \n",
      "Lyra                Lyra                \n",
      "McKee               McKee               \n",
      ",                   ,                   \n",
      "said                say                 \n",
      "it                  it                  \n",
      "would               would               \n",
      "be                  be                  \n",
      "``                  ``                  \n",
      "remiss              remiss              \n",
      "''                  ''                  \n",
      "of                  of                  \n",
      "them                them                \n",
      "not                 not                 \n",
      "to                  to                  \n",
      "take                take                \n",
      "advantage           advantage           \n",
      "of                  of                  \n",
      "the                 the                 \n",
      "row                 row                 \n",
      "over                over                \n",
      "the                 the                 \n",
      "Northern            Northern            \n",
      "Irish               Irish               \n",
      "border              border              \n",
      ".                   .                   \n",
      "But                 But                 \n",
      "in                  in                  \n",
      "an                  an                  \n",
      "interview           interview           \n",
      "with                with                \n",
      "the                 the                 \n",
      "Sunday              Sunday              \n",
      "Times               Times               \n",
      ",                   ,                   \n",
      "representatives     representatives     \n",
      "admitted            admit               \n",
      "their               their               \n",
      "campaign            campaign            \n",
      "of                  of                  \n",
      "violence            violence            \n",
      "had                 have                \n",
      "no                  no                  \n",
      "chance              chance              \n",
      "of                  of                  \n",
      "achieving           achieve             \n",
      "their               their               \n",
      "goal                goal                \n",
      "of                  of                  \n",
      "a                   a                   \n",
      "united              unite               \n",
      "Ireland             Ireland             \n",
      ".                   .                   \n",
      "They                They                \n",
      "said                say                 \n",
      ":                   :                   \n",
      "``                  ``                  \n",
      "The                 The                 \n",
      "attacks             attack              \n",
      "are                 be                  \n",
      "symbolic            symbolic            \n",
      ".                   .                   \n",
      "They                They                \n",
      "are                 be                  \n",
      "propaganda          propaganda          \n",
      ".                   .                   \n",
      "As                  As                  \n",
      "long                long                \n",
      "as                  as                  \n",
      "you                 you                 \n",
      "have                have                \n",
      "the                 the                 \n",
      "British             British             \n",
      "in                  in                  \n",
      "Ireland             Ireland             \n",
      "and                 and                 \n",
      "the                 the                 \n",
      "country             country             \n",
      "remains             remain              \n",
      "partitioned         partition           \n",
      ",                   ,                   \n",
      "there               there               \n",
      "will                will                \n",
      "be                  be                  \n",
      "an                  an                  \n",
      "IRA                 IRA                 \n",
      ".                   .                   \n",
      "''                  ''                  \n",
      "One                 One                 \n",
      "dissident           dissident           \n",
      "told                tell                \n",
      "the                 the                 \n",
      "Times               Times               \n",
      ":                   :                   \n",
      "``                  ``                  \n",
      "Brexit              Brexit              \n",
      "has                 have                \n",
      "forced              force               \n",
      "the                 the                 \n",
      "IRA                 IRA                 \n",
      "to                  to                  \n",
      "refocus             refocus             \n",
      "and                 and                 \n",
      "has                 have                \n",
      "underlined          underline           \n",
      "how                 how                 \n",
      "Ireland             Ireland             \n",
      "remains             remain              \n",
      "partitioned         partition           \n",
      ".                   .                   \n",
      "It                  It                  \n",
      "would               would               \n",
      "be                  be                  \n",
      "remiss              remiss              \n",
      "of                  of                  \n",
      "us                  us                  \n",
      "not                 not                 \n",
      "to                  to                  \n",
      "capitalise          capitalise          \n",
      "on                  on                  \n",
      "the                 the                 \n",
      "opportunity         opportunity         \n",
      "''                  ''                  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLemas\")\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "for palabra in words:\n",
    "    print (\"{0:20}{1:20}\".format(palabra,wordnet_lemmatizer.lemmatize(palabra, pos=\"v\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realice un análisis morfológico de los términos incluidos. Utilice nltk.pos_tag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Morfologico:  [('Pese', 'VB'), ('a', 'DT'), ('las', 'NN'), ('cada', 'NN'), ('vez', 'NN'), ('más', 'NN'), ('duras', 'FW'), ('demandas', 'FW'), ('de', 'FW'), ('capital', 'NN'), ('la', 'NN'), ('banca', 'NN'), ('española', 'NN'), ('ha', 'NN'), ('logrado', 'NN'), ('superar', 'NN'), ('las', 'NNS'), ('nuevas', 'JJ'), ('exigencias', 'NNS'), (',', ','), ('con', 'NN'), ('lo', 'NN'), ('que', 'NN'), ('no', 'DT'), ('tienen', 'NN'), ('limitaciones', 'VBZ'), ('para', 'JJ'), ('repartir', 'NN'), ('dividendo', 'NN'), (',', ','), ('pagar', 'NN'), ('bonus', 'VBD'), ('a', 'DT'), ('sus', 'NN'), ('directivos', 'NN'), ('o', 'NN'), ('abonar', 'IN'), ('los', 'JJ'), ('cupones', 'NNS'), ('de', 'IN'), ('los', 'FW'), ('bonos', 'JJ'), ('convertibles', 'NNS'), ('a', 'DT'), ('lo', 'JJ'), ('largo', 'NN'), ('del', 'NN'), ('presente', 'NN'), ('ejericico', 'NN'), ('.', '.'), ('No', 'DT'), ('obstante', 'NN'), (',', ','), ('los', 'JJ'), ('supervisores', 'NNS'), ('mantienen', 'VBP'), ('su', 'JJ'), ('objetivo', 'FW'), ('de', 'FW'), ('elevar', 'FW'), ('los', 'JJ'), ('ratios', 'NNS'), ('de', 'IN'), ('capital', 'NN'), ('para', 'NN'), ('el', 'NN'), ('presente', 'NN'), ('ejercicio', 'NN'), (',', ','), ('“', 'NNP'), ('y', 'NNP'), ('lo', 'VBZ'), ('mismo', 'FW'), ('harán', 'NN'), ('para', 'NN'), ('2020', 'CD'), ('”', 'NN'), (',', ','), ('explica', 'VBP'), ('otra', 'JJ'), ('fuente', 'NN'), ('financiera', 'NN'), ('.', '.'), ('De', 'NNP'), ('momento', 'FW'), (',', ','), ('Deutsche', 'NNP'), ('Bank', 'NNP'), ('e', 'IN'), ('ING', 'NNP'), ('son', 'NN'), ('los', 'NN'), ('bancos', 'VBD'), ('a', 'DT'), ('los', 'NN'), ('que', 'NN'), ('se', 'NN'), ('les', 'VBZ'), ('exige', 'FW'), ('más', 'FW'), ('requerimientos', 'FW'), ('de', 'FW'), ('capital', 'NN'), ('total', 'NN'), (',', ','), ('seguido', 'NN'), ('de', 'FW'), ('BNG', 'NNP'), ('también', 'NN'), ('de', 'IN'), ('los', 'FW'), ('Países', 'NNP'), ('Bajos', 'NNP'), (',', ','), ('al', 'NN'), ('alemán', 'NN'), ('Commezbank', 'NNP'), ('(', '('), ('que', 'JJ'), ('negocia', 'RB'), ('su', 'JJ'), ('fusión', 'JJ'), ('con', 'NN'), ('Deutsche', 'NNP'), ('Bank', 'NNP'), (')', ')'), (',', ','), ('y', 'VBZ'), ('a', 'DT'), ('al', 'JJ'), ('italiano', 'NN'), ('Monte', 'NNP'), ('dei', 'FW'), ('Paschi', 'NNP'), ('dei', 'FW'), ('Siena', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "palabras_morf = nltk.pos_tag(palabras)\n",
    "print(\"\\nMorfologico: \", palabras_morf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Morfologico:  [('The', 'DT'), ('New', 'NNP'), ('IRA', 'NNP'), ('are', 'VBP'), ('capitalising', 'VBG'), ('on', 'IN'), ('Brexit', 'NNP'), ('to', 'TO'), ('recruit', 'VB'), (',', ','), ('senior', 'JJ'), ('members', 'NNS'), ('have', 'VBP'), ('admitted', 'VBN'), ('.', '.'), ('The', 'DT'), ('Paramilitary', 'NNP'), ('group', 'NN'), (',', ','), ('who', 'WP'), ('last', 'JJ'), ('week', 'NN'), ('accepted', 'VBD'), ('responsibility', 'NN'), ('for', 'IN'), ('the', 'DT'), ('killing', 'NN'), ('of', 'IN'), ('journalist', 'NN'), ('Lyra', 'NNP'), ('McKee', 'NNP'), (',', ','), ('said', 'VBD'), ('it', 'PRP'), ('would', 'MD'), ('be', 'VB'), ('``', '``'), ('remiss', 'JJ'), (\"''\", \"''\"), ('of', 'IN'), ('them', 'PRP'), ('not', 'RB'), ('to', 'TO'), ('take', 'VB'), ('advantage', 'NN'), ('of', 'IN'), ('the', 'DT'), ('row', 'NN'), ('over', 'IN'), ('the', 'DT'), ('Northern', 'NNP'), ('Irish', 'NNP'), ('border', 'NN'), ('.', '.'), ('But', 'CC'), ('in', 'IN'), ('an', 'DT'), ('interview', 'NN'), ('with', 'IN'), ('the', 'DT'), ('Sunday', 'NNP'), ('Times', 'NNP'), (',', ','), ('representatives', 'NNS'), ('admitted', 'VBD'), ('their', 'PRP$'), ('campaign', 'NN'), ('of', 'IN'), ('violence', 'NN'), ('had', 'VBD'), ('no', 'DT'), ('chance', 'NN'), ('of', 'IN'), ('achieving', 'VBG'), ('their', 'PRP$'), ('goal', 'NN'), ('of', 'IN'), ('a', 'DT'), ('united', 'JJ'), ('Ireland', 'NNP'), ('.', '.'), ('They', 'PRP'), ('said', 'VBD'), (':', ':'), ('``', '``'), ('The', 'DT'), ('attacks', 'NNS'), ('are', 'VBP'), ('symbolic', 'JJ'), ('.', '.'), ('They', 'PRP'), ('are', 'VBP'), ('propaganda', 'RB'), ('.', '.'), ('As', 'RB'), ('long', 'RB'), ('as', 'IN'), ('you', 'PRP'), ('have', 'VBP'), ('the', 'DT'), ('British', 'JJ'), ('in', 'IN'), ('Ireland', 'NNP'), ('and', 'CC'), ('the', 'DT'), ('country', 'NN'), ('remains', 'VBZ'), ('partitioned', 'JJ'), (',', ','), ('there', 'EX'), ('will', 'MD'), ('be', 'VB'), ('an', 'DT'), ('IRA', 'NNP'), ('.', '.'), (\"''\", \"''\"), ('One', 'CD'), ('dissident', 'NN'), ('told', 'VBD'), ('the', 'DT'), ('Times', 'NNP'), (':', ':'), ('``', '``'), ('Brexit', 'NN'), ('has', 'VBZ'), ('forced', 'VBN'), ('the', 'DT'), ('IRA', 'NNP'), ('to', 'TO'), ('refocus', 'VB'), ('and', 'CC'), ('has', 'VBZ'), ('underlined', 'VBN'), ('how', 'WRB'), ('Ireland', 'NNP'), ('remains', 'VBZ'), ('partitioned', 'VBN'), ('.', '.'), ('It', 'PRP'), ('would', 'MD'), ('be', 'VB'), ('remiss', 'NN'), ('of', 'IN'), ('us', 'PRP'), ('not', 'RB'), ('to', 'TO'), ('capitalise', 'VB'), ('on', 'IN'), ('the', 'DT'), ('opportunity', 'NN'), (\"''\", \"''\")]\n"
     ]
    }
   ],
   "source": [
    "palabras_MorfIngles = nltk.pos_tag(words)\n",
    "print(\"\\nMorfologico: \", palabras_MorfIngles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraiga entidades con la función nltk.ne_chunk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que nos muestra el banco Monte Paschi Siena como si fuese una persona, lo correcto sería que lo reconociera como una organización al tratarse de un banco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPE De\n",
      "PERSON Deutsche Bank\n",
      "ORGANIZATION BNG\n",
      "PERSON Países Bajos\n",
      "ORGANIZATION Commezbank\n",
      "PERSON Deutsche Bank\n",
      "PERSON Monte\n",
      "PERSON Paschi\n",
      "PERSON Siena\n"
     ]
    }
   ],
   "source": [
    "for sent in nltk.sent_tokenize(texto_espanol):\n",
    "   for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "      if hasattr(chunk, 'label'):\n",
    "         print(chunk.label(), ' '.join(c[0] for c in chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORGANIZATION New\n",
      "GPE Brexit\n",
      "ORGANIZATION Paramilitary\n",
      "PERSON Lyra McKee\n",
      "LOCATION Northern Irish\n",
      "GPE Ireland\n",
      "GPE British\n",
      "GPE Ireland\n",
      "ORGANIZATION IRA\n",
      "PERSON Brexit\n",
      "ORGANIZATION IRA\n",
      "GPE Ireland\n"
     ]
    }
   ],
   "source": [
    "for sent in nltk.sent_tokenize(texto_ingles):\n",
    "   for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "      if hasattr(chunk, 'label'):\n",
    "         print(chunk.label(), ' '.join(c[0] for c in chunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Una vez realizados todos los análisis, liste en pantalla las anotaciones obtenidas: frases, palabras, categoría gramatical del análisis morfológico, localizaciones, organizaciones y personas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un aspecto clave a la hora de realizar este análisis ha sido la normalización, ya que este proceso consiste en poner todo el texto en igualdad de condiciones para realizar un analisis mas preciso.\n",
    "La normalización se lleva a cabo a través de lematización. La lematización es un proceso lingüístico que consiste en, dada una forma flexionada (es decir, en plural, en femenino, conjugada, etc), hallar el lema correspondiente.\n",
    "Por tanto, con este proceso es donde se aprecia una mayor diferencia entre los dos idiomas que hemos escogido para analizar.\n",
    "\n",
    "El análisis morfólogico podemos ver que es más preciso en el idioma sajón que en el latino. Hemos detectado que nos reconocía 'las' como un nombre singular cuando en realidad es un artículo. Mientras que en el analisis morfologico en inglés no hemso apreciadp ningun error en la morfología de las palabras. Decimos entonces que contamso con más errores morfologicos en analisis de texto en castellano que en el inglés.\n",
    "\n",
    "Por último, en la extraccion de entidades, nos ha llamado la atención que el Banco Monte Paschi di Siena se reconociese como una persona y no como unn organización en el texto en español.\n",
    "\n",
    "Sin embargo, en el texto de inglés se ha reconocido perfectamente a IRA , que es el Ejercito Republicano Irlandés, como una organización. Aún asi, se reconoce Brexit como una persona pero no sabemos si esa clasificación seria la mas adecuada ya que se trata de una abreviatura de las palabras inglesas Britain (Gran Bretaña) y exit (salida), y es el término acuñado para referirse a la salida de Reino Unido de la Unión Europea (UE). Además se ha reconocido como una organizacion a Commezbank mientras que Deutsche Bank ha sido establecido como una persona, y ambso son bancos.\n",
    "\n",
    "En español\n",
    "\n",
    "*Organizaciones*: BNG.\n",
    "*Localizaciones*: Commezbank.\n",
    "*Personas*: Monte, Paschi, Siena.\n",
    "\n",
    "\n",
    "En inglés\n",
    "\n",
    "*Organizaciones*: IRA, Paramilitary.\n",
    "*Localizaciones*: Northern Irish.\n",
    "*Personas*: Brexit, Lyra McKee.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comente las diferencias entre los resultados obtenidos en español y en inglés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos unos resultados buenos para el análisis del texto en ingles y con algunos errores para el texto en castellano. Vemos que la tokenizacion y normalizacion si se realiza correctamente.\n",
    "En cuanto al análisis morfologico en castellano, sí apreciamos algunos errores a la hora de reconocer palabras por parte de NLTK. Esto nos hace pensar que podria ser motivo de que NLTK estás mas optimizado para un análisis de textos en inglés.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intente obtener mejores resultados en español. Para ello se sugiere utilizar la librería spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos la librería"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.es.examples import sentences "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se nos han faiclitado una serie de librerias que serían optimas para analizar noticias es_core_new_sm y que obtendría mejores resultados para el castellano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezaremos con el texto en inglés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(texto_ingles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun phrases: ['The New IRA', 'Brexit', 'senior members', 'The Paramilitary group', 'who', 'responsibility', 'the killing', 'journalist Lyra McKee', 'it', 'them', 'advantage', 'the row', 'the Northern Irish border', 'an interview', 'the Sunday Times', 'representatives', 'their campaign', 'violence', 'no chance', 'their goal', 'a united Ireland', 'They', 'The attacks', 'They', 'propaganda', 'you', 'the British', 'Ireland', 'the country', 'an IRA', 'One dissident', 'the Times', 'Brexit', 'the IRA', 'Ireland', 'It', 'us', 'the opportunity']\n"
     ]
    }
   ],
   "source": [
    "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbs: ['be', 'capitalise', 'recruit', 'have', 'admit', 'accept', 'say', 'would', 'be', 'take', 'admit', 'have', 'achieve', 'say', 'be', 'be', 'have', 'remain', 'partition', 'will', 'be', 'tell', 'have', 'force', 'refocus', 'have', 'underline', 'remain', 'would', 'be', 'capitalise']\n"
     ]
    }
   ],
   "source": [
    "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos lo mismo para el texto en Castellano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2=nlp(texto_espanol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun phrases: ['Pese a las cada', 'más duras', 'de capital', 'banca española', 'logrado superar las nuevas exigencias', 'no tienen', 'limitaciones para repartir dividendo', 'pagar bonus a sus directivos', 'los', 'mantienen su objetivo de elevar los ratios de capital para el presente ejercicio', '”, explica otra fuente financiera', 'De momento', 'e ING son los', 'de capital total', 'seguido de BNG también de los Países Bajos', 'al alemán Commezbank', 'fusión con Deutsche Bank', 'a al italiano Monte dei Paschi dei Siena']\n"
     ]
    }
   ],
   "source": [
    "print(\"Noun phrases:\", [chunk.text for chunk in doc2.noun_chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbs: ['pese', 'para', 'pagar', 'convertibl', 'su', 'lo', 'bancos', 'requerimiento', 'lo', 'su']\n"
     ]
    }
   ],
   "source": [
    "print(\"Verbs:\", [token.lemma_ for token in doc2 if token.pos_ == \"VERB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brexit ORG\n",
      "The Paramilitary ORG\n",
      "last week DATE\n",
      "Lyra McKee PERSON\n",
      "Northern Irish NORP\n",
      "the Sunday Times ORG\n",
      "Ireland GPE\n",
      "\n",
      " GPE\n",
      "British NORP\n",
      "Ireland GPE\n",
      "One CARDINAL\n",
      "Times ORG\n",
      "IRA ORG\n",
      "Ireland GPE\n"
     ]
    }
   ],
   "source": [
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez utilizada las librería Spacy si realiazamos una comparacion frente a NLTK, vemos que presenta peores resultados. Muestra como verbos palabras como para, bancos , lo etc. Lo que hace pensar que no consigue diferenciar bien la tipología de las palabras. No obstante, parece que mejora y reconoce aquellas palabras que se refieren a timepo como seria next week y para contrastar cn NLTK, aqui Brexit seria una organización mientras que en la otra librería era un nombre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUSIONES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta práctica hemos utlizado dos textos totalmente distintos pero de caracter informativo, uno era una noticia económica que habla de actividad financiera y de bancos, mientras que el otro es una noticia inglesa sobre el Brexit.\n",
    "Usando distintas librerias como son NLTK y Spacy, vemos que ambas tienen errores a la hora de analizar palabras en español mientras que su uso sobre el inglés es perfecto.\n",
    "Sin embargo usando Spacy, vemos que a la hora de clasificar las palabras mejora en cuanto a NLTK y las reconoce mejor. \n",
    "Por tanto, diriamos que usamos NLTK para cuando querramos analizar un texto en inglés y Spacy para cuando el texto se encuentre en castellano.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
